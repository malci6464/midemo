<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"><channel><title>malcolmisaacs.com</title><description>my blog on ai related topics</description><link>https://example.com/</link><item><title>Perceptron math part 2</title><link>https://example.com/blog/post-11/</link><guid isPermaLink="true">https://example.com/blog/post-11/</guid><description>Beyond the basic math, what do perceptrons have to do with modern learning and how can circumvate their limitations.</description><pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate></item><item><title>Perceptron math - part 1</title><link>https://example.com/blog/post-10/</link><guid isPermaLink="true">https://example.com/blog/post-10/</guid><description>Going down to a base level of the perceptron to ensure foundational understanding and intuition in general ML dev.</description><pubDate>Wed, 12 Nov 2025 00:00:00 GMT</pubDate></item><item><title>Fighting the regression</title><link>https://example.com/blog/post-9/</link><guid isPermaLink="true">https://example.com/blog/post-9/</guid><description>This is a journey through the trials, tactics, and surprises of building a reliable time series model despite relentless regression to the mean.</description><pubDate>Tue, 12 Nov 2024 00:00:00 GMT</pubDate></item><item><title>Tokenization</title><link>https://example.com/blog/post-8/</link><guid isPermaLink="true">https://example.com/blog/post-8/</guid><description>“Tokenization is at the heart of much weirdness of LLMs. Do not brush it off.” AK</description><pubDate>Wed, 28 Aug 2024 00:00:00 GMT</pubDate></item><item><title>Applied Ml resource</title><link>https://example.com/blog/post-7/</link><guid isPermaLink="true">https://example.com/blog/post-7/</guid><description>Thought I&apos;d share this awesome repo for applied ML from the prodigous blogger Eugene Yan :) - https://github.com/eugeneyan/applied-ml</description><pubDate>Thu, 22 Aug 2024 00:00:00 GMT</pubDate></item><item><title>Gradient checkpointing</title><link>https://example.com/blog/post-6/</link><guid isPermaLink="true">https://example.com/blog/post-6/</guid><description>Gradient checkpointing enables you to run a more powerful model on your machine - beneficial under training.</description><pubDate>Sun, 18 Aug 2024 00:00:00 GMT</pubDate></item><item><title>Batch processing</title><link>https://example.com/blog/post-1/</link><guid isPermaLink="true">https://example.com/blog/post-1/</guid><description>A crucial technique in training neural network (NN) models. Instead of processing individual data samples one at a time, batch processing groups multiple samples into batches and processes them simultaneously.</description><pubDate>Sat, 17 Aug 2024 00:00:00 GMT</pubDate></item><item><title>Software 2.0</title><link>https://example.com/blog/post-2/</link><guid isPermaLink="true">https://example.com/blog/post-2/</guid><description>In Software 2.0 most often the source code comprises the dataset that defines the desirable behavior....</description><pubDate>Sat, 17 Aug 2024 00:00:00 GMT</pubDate></item><item><title>Special token injection attacks</title><link>https://example.com/blog/post-4/</link><guid isPermaLink="true">https://example.com/blog/post-4/</guid><description>A special token is one designed to only be relevant to the model - such as &lt;|end_of_text|&gt;. These can cause standard software engineering bugs if handled poorly in the code.</description><pubDate>Sat, 17 Aug 2024 00:00:00 GMT</pubDate></item><item><title>GPU - Model memory</title><link>https://example.com/blog/post-5/</link><guid isPermaLink="true">https://example.com/blog/post-5/</guid><description>How much GPU do you need? State of the art performance requires state of the art machinery. A100&apos;s are not cheap!</description><pubDate>Sat, 17 Aug 2024 00:00:00 GMT</pubDate></item><item><title>RAG -&gt; stop hallucinations!</title><link>https://example.com/blog/post-3/</link><guid isPermaLink="true">https://example.com/blog/post-3/</guid><description>Using them in a RAG architecture brings some different constraints to the table. I think the biggest one is the expectation, especially in a corporate setting, for being factual. But this is not the strength of an LLM. In fact many have deemed the ‘hallucination problem’ a feature and not a bug....</description><pubDate>Sat, 17 Aug 2024 00:00:00 GMT</pubDate></item></channel></rss>